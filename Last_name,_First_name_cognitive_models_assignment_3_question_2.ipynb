{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxrusk/m/blob/main/Last_name%2C_First_name_cognitive_models_assignment_3_question_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2. Multigenerational Individual and Population Belief Updating**\n",
        "\n",
        "## Below we define a model about the *individual's* updating cognitive beliefs based on observations using Bayesian inference."
      ],
      "metadata": {
        "id": "HVJvUtQMJhK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def update_beliefs(prior_mean, prior_variance, observations, observation_variance):\n",
        "      # Update beliefs based on observations using Bayesian inference.\n",
        "\n",
        "      likelihood_mean = np.mean(observations)\n",
        "      posterior_variance = 1 / (1 / prior_variance + len(observations) / observation_variance)\n",
        "      posterior_mean = posterior_variance * (prior_mean / prior_variance + sum(observations) / observation_variance)\n",
        "      return posterior_mean, posterior_variance\n",
        "\n",
        "def simulate_individual_belief_evolution(true_theta, prior_mean, prior_variance, observation_variance, observations_per_generation, num_generations):\n",
        "    generation_means = [prior_mean]\n",
        "    generation_variances = [prior_variance]\n",
        "\n",
        "    for g in range(num_generations):\n",
        "        observations = np.random.normal(true_theta, np.sqrt(observation_variance), observations_per_generation)\n",
        "        posterior_mean, posterior_variance = update_beliefs(generation_means[-1], generation_variances[-1], observations, observation_variance)\n",
        "        generation_means.append(posterior_mean)\n",
        "        generation_variances.append(posterior_variance)\n",
        "\n",
        "        # Calculate 95% Confidence Interval for the current generation\n",
        "        ci_lower = posterior_mean - 1.96 * np.sqrt(posterior_variance)\n",
        "        ci_upper = posterior_mean + 1.96 * np.sqrt(posterior_variance)\n",
        "\n",
        "        # Print out the estimated mean and CI for the current generation\n",
        "        print(f\"Generation {g+1}: Estimated Mean = {posterior_mean:.2f}, 95% CI = [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
        "\n",
        "    # Plotting the evolution of beliefs across generations\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(num_generations + 1), generation_means, marker='o', label='Estimated Mean')\n",
        "    plt.fill_between(range(num_generations + 1),\n",
        "                     np.array(generation_means) - 1.96 * np.sqrt(generation_variances),\n",
        "                     np.array(generation_means) + 1.96 * np.sqrt(generation_variances),\n",
        "                     color='blue', alpha=0.2, label='95% Confidence Interval')\n",
        "    plt.axhline(y=true_theta, color='r', linestyle='-', label='True State')\n",
        "    plt.xlabel('Generation')\n",
        "    plt.ylabel('Belief about θ')\n",
        "    plt.title(\"Evolution of an Individual's Beliefs Across Generations\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "K-ONJkxQOX_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2a. The cell below defines a set of parameter values for running the model. Execute the cell three times (you may need to copy and paste it for each run), and then describe the meanings of the parameters and the resulting outputs in your own words.**"
      ],
      "metadata": {
        "id": "EUCIJcXkKlfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "true_theta = 50\n",
        "prior_mean = 40\n",
        "prior_variance = 100\n",
        "observation_variance = 25\n",
        "observations_per_generation = 1\n",
        "num_generations = 10\n",
        "\n",
        "simulate_individual_belief_evolution(true_theta, prior_mean, prior_variance, observation_variance, observations_per_generation, num_generations)"
      ],
      "metadata": {
        "id": "GG5oEBYRPMJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we are going to define a *population* model of non-social and social bilief updating across generations."
      ],
      "metadata": {
        "id": "pPwxGLHKLckz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_learning_scenarios(true_theta, prior_mean, prior_variance, observation_variance,\n",
        "                               num_generations, population_size, observations_per_generation, sample_size):\n",
        "    def update_beliefs(prior_mean, prior_variance, observations, observation_variance):\n",
        "        # Standard Bayesian update using private observations.\n",
        "        likelihood_mean = np.mean(observations)\n",
        "        posterior_variance = 1 / (1 / prior_variance + len(observations) / observation_variance)\n",
        "        posterior_mean = posterior_variance * (prior_mean / prior_variance + sum(observations) / observation_variance)\n",
        "        return posterior_mean, posterior_variance\n",
        "\n",
        "    def update_beliefs_social(prior_mean, prior_variance, social_means, social_variances):\n",
        "        # Bayesian update combining the agent’s own prior with social signals.\n",
        "        # Here, each social signal is the previous generation’s posterior belief (mean and variance).\n",
        "        prior_precision = 1.0 / prior_variance\n",
        "        social_precision_sum = sum(1.0 / sv for sv in social_variances)\n",
        "        total_precision = prior_precision + social_precision_sum\n",
        "        posterior_variance = 1.0 / total_precision\n",
        "        weighted_sum = prior_mean / prior_variance + sum(sm / sv for sm, sv in zip(social_means, social_variances))\n",
        "        posterior_mean = posterior_variance * weighted_sum\n",
        "        return posterior_mean, posterior_variance\n",
        "\n",
        "    def simulate_generation(population_means, population_variances, true_theta, observation_variance, observations_per_individual):\n",
        "        # Non-social learning: each individual gathers private observations.\n",
        "        new_means = []\n",
        "        new_variances = []\n",
        "        for mean, variance in zip(population_means, population_variances):\n",
        "            observations = np.random.normal(true_theta, np.sqrt(observation_variance), observations_per_individual)\n",
        "            posterior_mean, posterior_variance = update_beliefs(mean, variance, observations, observation_variance)\n",
        "            new_means.append(posterior_mean)\n",
        "            new_variances.append(posterior_variance)\n",
        "        return new_means, new_variances\n",
        "\n",
        "    def simulate_generation_with_random_sampling(population_means, population_variances, true_theta, observation_variance, observations_per_individual, sample_size):\n",
        "        # Social learning: each individual updates its belief by observing a random sample of peers\n",
        "        # (i.e. their posterior means and variances) from the previous generation.\n",
        "        new_means = []\n",
        "        new_variances = []\n",
        "        pop_size = len(population_means)\n",
        "        for i in range(pop_size):\n",
        "            sampled_indices = np.random.choice(pop_size, sample_size, replace=True)\n",
        "            social_means = [population_means[idx] for idx in sampled_indices]\n",
        "            social_variances = [population_variances[idx] for idx in sampled_indices]\n",
        "            posterior_mean, posterior_variance = update_beliefs_social(population_means[i],\n",
        "                                                                       population_variances[i],\n",
        "                                                                       social_means,\n",
        "                                                                       social_variances)\n",
        "            new_means.append(posterior_mean)\n",
        "            new_variances.append(posterior_variance)\n",
        "        return new_means, new_variances\n",
        "\n",
        "    def simulate_population_evolution(num_generations, population_size, true_theta, prior_mean, prior_variance,\n",
        "                                      observation_variance, observations_per_individual, social=False, sample_size=20):\n",
        "        # All individuals start with the same prior.\n",
        "        population_means = np.array([prior_mean] * population_size, dtype=float)\n",
        "        population_variances = np.array([prior_variance] * population_size, dtype=float)\n",
        "        individual_means_over_time = [population_means.copy()]\n",
        "        individual_variances_over_time = [population_variances.copy()]\n",
        "\n",
        "        for g in range(num_generations):\n",
        "            if social:\n",
        "                if g == 0:\n",
        "                    # Bootstrap: first update is private so that beliefs shift away from the prior.\n",
        "                    population_means, population_variances = simulate_generation(\n",
        "                        population_means, population_variances, true_theta, observation_variance, observations_per_individual)\n",
        "                else:\n",
        "                    # Pure social update: each individual observes the previous generation’s posteriors.\n",
        "                    population_means, population_variances = simulate_generation_with_random_sampling(\n",
        "                        population_means, population_variances, true_theta, observation_variance, observations_per_individual, sample_size)\n",
        "            else:\n",
        "                # Non-social: every generation gathers private observations.\n",
        "                population_means, population_variances = simulate_generation(\n",
        "                    population_means, population_variances, true_theta, observation_variance, observations_per_individual)\n",
        "\n",
        "            individual_means_over_time.append(population_means.copy())\n",
        "            individual_variances_over_time.append(population_variances.copy())\n",
        "\n",
        "        return np.array(individual_means_over_time), np.array(individual_variances_over_time)\n",
        "\n",
        "    # Run the simulations.\n",
        "    non_social_means_over_time, non_social_variances_over_time = simulate_population_evolution(\n",
        "        num_generations, population_size, true_theta, prior_mean, prior_variance, observation_variance,\n",
        "        observations_per_generation, social=False)\n",
        "\n",
        "    social_means_over_time, social_variances_over_time = simulate_population_evolution(\n",
        "        num_generations, population_size, true_theta, prior_mean, prior_variance, observation_variance,\n",
        "        observations_per_generation, social=True, sample_size=sample_size)\n",
        "\n",
        "    # Compute average means and convergence error.\n",
        "    average_non_social_means = np.mean(non_social_means_over_time, axis=1)\n",
        "    average_social_means = np.mean(social_means_over_time, axis=1)\n",
        "\n",
        "    error_non_social = np.abs(average_non_social_means - true_theta)\n",
        "    error_social = np.abs(average_social_means - true_theta)\n",
        "\n",
        "    # Plot individual trajectories.\n",
        "    fig, axes = plt.subplots(1,2, figsize=(14,6))\n",
        "    for i in range(population_size):\n",
        "        axes[0].plot(range(num_generations+1), non_social_means_over_time[:, i], alpha=0.3, lw=1)\n",
        "    axes[0].set_title('Non-Social Learning')\n",
        "    axes[0].axhline(y=true_theta, color='r', linestyle='-', label='True θ')\n",
        "    axes[0].set_xlabel('Generation')\n",
        "    axes[0].set_ylabel('Belief about θ')\n",
        "\n",
        "    for i in range(population_size):\n",
        "        axes[1].plot(range(num_generations+1), social_means_over_time[:, i], alpha=0.3, lw=1)\n",
        "    axes[1].set_title('Social Learning')\n",
        "    axes[1].axhline(y=true_theta, color='r', linestyle='-', label='True θ')\n",
        "    axes[1].set_xlabel('Generation')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot convergence error over generations.\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(range(num_generations+1), error_non_social, marker='o', linestyle='--', color='darkorange', label='Non-Social Error')\n",
        "    plt.plot(range(num_generations+1), error_social, marker='s', linestyle='-', color='purple', label='Social Error')\n",
        "    plt.xlabel('Generation')\n",
        "    plt.ylabel('Absolute Error |mean - true θ|')\n",
        "    plt.title('Convergence Error Over Generations')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot the means and 95% confidence intervals.\n",
        "    ci_non_social = np.var(non_social_means_over_time, axis=1, ddof=1)\n",
        "    ci_social = np.var(social_means_over_time, axis=1, ddof=1)\n",
        "\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(range(num_generations+1), average_non_social_means, marker='o', linestyle='--', color='darkorange', label='Non-Social Mean')\n",
        "    plt.fill_between(range(num_generations+1), average_non_social_means - 2*np.sqrt(ci_non_social),\n",
        "                     average_non_social_means + 2*np.sqrt(ci_non_social), color='orange', alpha=0.1, label='Non-Social 95% CI')\n",
        "    plt.plot(range(num_generations+1), average_social_means, marker='s', linestyle='-', color='purple', label='Social Mean')\n",
        "    plt.fill_between(range(num_generations+1), average_social_means - 2*np.sqrt(ci_social),\n",
        "                     average_social_means + 2*np.sqrt(ci_social), color='violet', alpha=0.1, label='Social 95% CI')\n",
        "    plt.axhline(y=true_theta, color='r', linestyle='-', label='True θ')\n",
        "    plt.xlabel('Generation')\n",
        "    plt.ylabel('Mean Belief and Confidence Interval')\n",
        "    plt.title('Mean Beliefs and 95% CI Over Generations')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print generation-by-generation results.\n",
        "    for g in range(num_generations+1):\n",
        "        ns_ci_lower = average_non_social_means[g] - 2*np.sqrt(ci_non_social[g])\n",
        "        ns_ci_upper = average_non_social_means[g] + 2*np.sqrt(ci_non_social[g])\n",
        "        s_ci_lower = average_social_means[g] - 2*np.sqrt(ci_social[g])\n",
        "        s_ci_upper = average_social_means[g] + 2*np.sqrt(ci_social[g])\n",
        "        print(f\"Generation {g}:\")\n",
        "        print(f\"  Non-Social: Mean = {average_non_social_means[g]:.2f}, Error = {error_non_social[g]:.2f}, 95% CI = [{ns_ci_lower:.2f}, {ns_ci_upper:.2f}]\")\n",
        "        print(f\"  Social:     Mean = {average_social_means[g]:.2f}, Error = {error_social[g]:.2f}, 95% CI = [{s_ci_lower:.2f}, {s_ci_upper:.2f}]\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IEO9qpAAjiSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2b. Now, we run the model to compare multigenerational population dynamics under non-social and social learning. Execute the model below and describe the simulations in your own words, including the parameters, generated figures, *and* results.**"
      ],
      "metadata": {
        "id": "xJDidLLGL7FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and paste this cell to run the function with different sets of parameters\n",
        "compare_learning_scenarios(\n",
        "    true_theta=50,\n",
        "    prior_mean=40,\n",
        "    prior_variance=100,\n",
        "    observation_variance=25,\n",
        "    num_generations=10,\n",
        "    population_size=100,\n",
        "    observations_per_generation=1,   #for non-social learning\n",
        "    sample_size=1                    #for social learning\n",
        ")"
      ],
      "metadata": {
        "id": "OORc_c8vjkwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2c. Exploring the Impact of Observations and Sample Size: The previous tests assumed observations_per_generation = 1 for non-social learning and sample_size = 1 for social learning. Now, adjust both parameters to 2, 3, 5, 10, and 20, respectively. Run the model for each parameter set (you may need to copy and paste the previous cell for each run), then observe and compare the results as these values increase. How do these changes impact the outcomes? Specifically, from a \"socio-cognitive\" perspective: (i) Do your experiments provide an good illustration that social learning require less effort and fewer cognitive resources compared to non-social learning, as claimed by Hardy et al. (2022)? (ii) Do your experiments provide an good illustration of \"rational information accumulation\" through social learning, as described by Hardy et al. (2022), or do they suggest that cognitive biases may emerge as a result of social learning?**"
      ],
      "metadata": {
        "id": "ei3pgn27MvqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2d. Exploring an Additional Parameter in Belief Updating: Now, select one additional parameter (other than observations_per_generation and sample_size) that you believe is relevant to the cognitive aspects of non-social and social belief updating. Run the model using three different values for this parameter. How do these changes impact the outcomes? Specifically, from a \"socio-cognitive\" perspective: (i) Do your experiments provide an good illustration that social learning require less effort and fewer cognitive resources compared to non-social learning, as claimed by Hardy et al. (2022)? (ii) Do your experiments provide an good illustration of \"rational information accumulation\" through social learning, as described by Hardy et al. (2022), or do they suggest that cognitive biases may emerge as a result of social learning?**"
      ],
      "metadata": {
        "id": "b1gCGX8UNl7e"
      }
    }
  ]
}